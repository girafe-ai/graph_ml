{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment — Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on Colab uncomment this cell\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.metrics import balanced_accuracy_score, mean_squared_error\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/netspractice/network-science/main/datasets/569720_ego_pokec.gml\"\n",
    "open(\"569720_ego_pokec.gml\", \"wb\").write(requests.get(url).content)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/netspractice/network-science/main/datasets/musae_facebook_ego_802.gml\"\n",
    "open(\"musae_facebook_ego_802.gml\", \"wb\").write(requests.get(url).content)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/netspractice/network-science/main/datasets/polblogs.gml\"\n",
    "open(\"polblogs.gml\", \"wb\").write(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1. Assortativity analysis (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the structure of the network is known but the labels of the nodes are hidden, we would like to select a small subset of nodes such that, if we knew their labels, we could accurately predict the labels of all the other nodes. However, it makes sence if labels depend of network structure. A few next models work well upon the assumption of high assortativity mixing. Let us remind that assortative mixing is the tendency for nodes to be connected to other nodes that are like them in some way. Assortativity coefficient bounded by\n",
    "\n",
    "$$-1 \\leq r \\leq 1$$\n",
    "\n",
    "where $r \\to -1$ means that nodes tend to connect to nodes of the another class, $r \\to 1$ — to the same class. Therefore, randomly mixed networks show $r \\to 0$ for binary and numeric features, and $r < 0$ for categorical features. \n",
    "\n",
    "First, let us check assortativity coefficient for some networks and try to understand which labels can be predicted via network structure.\n",
    "\n",
    "Write a function `assortativity_coefficients` that takes a graph, an optional list of categorical (or binary) features, an optional list of numerical features and returns a dictionary where a key is a feature name and value is assoratitvity coefficient. _Use `nx.attribute_assortativity_coefficient` and `nx.numeric_assortativity_coefficient`._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cc5ce921056c789850c6eff145ceb8d1",
     "grade": false,
     "grade_id": "cell-5a7b9606f5363a00",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def assortativity_coefficients(G, categorical=[], numerical=[]):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a subgraph of Slovakian online social network [Pokec](http://snap.stanford.edu/data/soc-Pokec.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d1376320e445255d0aeeee9fc8f653d6",
     "grade": true,
     "grade_id": "cell-fbebfac30bdf2aa3",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"569720_ego_pokec.gml\")\n",
    "coef = assortativity_coefficients(\n",
    "    G, [\"public\", \"gender\", \"region\"], [\"age\", \"completion_percentage\"]\n",
    ")\n",
    "assert len(coef) == 5\n",
    "assert round(sum(coef.values()), 4) == 0.2832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(coef, index=[\"assortativity\"]).T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `public` is 1 if a person publishes his list of friends, and 0 otherwise\n",
    "* `gender` is 1 for male and 0 for female\n",
    "* `region` is a region of residence\n",
    "* `age` is integer age\n",
    "* `completion_percentage` is a percentage of completion information about a person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, look at a network of [political blogosphere in the 2004 US Election](http://www-personal.umich.edu/~mejn/netdata/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"polblogs.gml\")\n",
    "coef = assortativity_coefficients(G, [\"value\", \"source\"])\n",
    "pd.DataFrame(coef, index=[\"assortativity\"]).T.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The attribute `value` is political leaning that is divided into liberal and conservative. Also there is a category `source` where this information taken from.\n",
    "\n",
    "Next, look at subgraph of the [Facebook large page-page network](http://snap.stanford.edu/data/facebook-large-page-page-network.html) restricted to pages from 4 categories which are defined by Facebook. These categories are: politicians, governmental organizations, television shows and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"musae_facebook_ego_802.gml\")\n",
    "coef = round(assortativity_coefficients(G, [\"value\"])[\"value\"], 2)\n",
    "print(\"category:\", coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to check numeric features is to calculate correlation of nodes attributes by edges. Let us again loook at attribute `age` in Pokec network. Let us draw a scatterplot with edges where $x$ is an age of the first node and $y$ is an age of the second node in each edge.\n",
    "\n",
    "Write a function `age_by_edges` that takes Pokec network and returns a tuple of two np.arrays:\n",
    "* age of the first node in edge\n",
    "* age of the second node in edge\n",
    "\n",
    "Size of each array is the number of edges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d475c8d0868e26fce1578ddc9e65c662",
     "grade": false,
     "grade_id": "cell-84d1a9df1c68712d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def age_by_edges(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d938bd7c4230b744c9534608c59eade7",
     "grade": true,
     "grade_id": "cell-20757093a39bc31b",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"569720_ego_pokec.gml\")\n",
    "x, y = age_by_edges(G)\n",
    "corrcoef = np.corrcoef(x, y)[0, 1]\n",
    "assert round(corrcoef, 4) == 0.2422"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.title(\"Correlation : {:.2f}\".format(corrcoef))\n",
    "plt.xlabel(\"age\")\n",
    "plt.ylabel(\"age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also it could be useful to transform a graph into bipartite and try to find a stronger dependency. For example, let us look at the attribute `age` in edges that connect nodes with opposite `gender`.\n",
    "\n",
    "Write a function `age_by_gender` that takes Pokec network and returns a tuple of two np.arrays:\n",
    "* age of a male node in edge (`gender = 1`)\n",
    "* age of a female node in edge\n",
    "\n",
    "Size of each array is the number of edges that connect nodes with opposite `gender`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e107883f3db0c449078453772ed9b8b",
     "grade": false,
     "grade_id": "cell-79d203a5db9b9c85",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def age_by_gender(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ae09e94a5bd4c28f1267ef4d17617476",
     "grade": true,
     "grade_id": "cell-d81c5fe8776e8ac1",
     "locked": true,
     "points": 0.25,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x, y = age_by_gender(G)\n",
    "corrcoef = np.corrcoef(x, y)[0, 1]\n",
    "assert round(corrcoef, 4) == 0.2214"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x, y, s=10)\n",
    "plt.title(\"Correlation : {:.2f}\".format(corrcoef))\n",
    "plt.xlabel(\"age, male\")\n",
    "plt.ylabel(\"age, female\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can find and drop outliers to increase correlation. For example, there are two significant outliers in the area $y>100$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 5))\n",
    "plt.scatter(x[y < 100], y[y < 100], s=10)\n",
    "plt.title(\"Correlation : {:.2f}\".format(np.corrcoef(x[y < 100], y[y < 100])[0, 1]))\n",
    "plt.xlabel(\"age, male\")\n",
    "plt.ylabel(\"age, female\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see some domain knowledge can help to preprocess the graph to get a better result for classification/regression tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2. Relational Neighbor Classifier (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us start again with the facebook dataset and try to predict a page category (0.78 assortativity coefficient): politicians, governmental organizations, television shows and companies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.read_gml(\"musae_facebook_ego_802.gml\")\n",
    "G = nx.convert_node_labels_to_integers(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare train and test sets of nodes to classification. Let us randomly select 30% of nodes as a train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_nodes = np.random.choice(G, size=int(0.3 * len(G)), replace=False)\n",
    "test_nodes = np.array(list(set(G.nodes).difference(train_nodes)))\n",
    "\n",
    "values = np.array(list(nx.get_node_attributes(G, \"value\").values()))\n",
    "y_train_temp = values[train_nodes]\n",
    "y_test_temp = values[test_nodes]\n",
    "\n",
    "print(y_train_temp[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert labels into integers for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique = list(set(values))\n",
    "y_train = np.array([unique.index(val) for val in y_train_temp])\n",
    "y_test = np.array([unique.index(val) for val in y_test_temp])\n",
    "print(y_train[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us denote $y_i$ as label of node $i$. Relational Neighbor Classifier based on a simple iterative procedure\n",
    "\n",
    "$$P(y_i = c|\\mathcal N(i)) = \\frac{1}{Z}\\sum_{j \\in \\mathcal N(i)}A_{ij}P(y_j = c|\\mathcal N(j))$$\n",
    "\n",
    "where $Z$ is a normalizing constant, $\\mathcal N(i)$ is neighbors of node $i$. Note that this approuch based on an assumption of strong assortativity: nodes related to each other are similar and likely belong to the same class. The algorithm is:\n",
    "\n",
    "1. Set an initial conditional distribution $\\Phi_0$. Train nodes have a probability one in truth class and zeros in others. Test nodes have an equal probability of each class.\n",
    "2. Update $\\Phi$ only for test nodes by the equation above\n",
    "3. Repeat 2 until converges: $\\Vert \\Phi_{i+1} - \\Phi_i \\Vert < \\varepsilon$\n",
    "4. Predictions are labels with maximal probability\n",
    "\n",
    "There is a function `relational_neighbor` that predicts labels. Parameters are:\n",
    "* `G`: graph\n",
    "* `threshold`: convergence threshold\n",
    "* `y_train`: np.array, labels for train nodes\n",
    "* `train_nodes`: np.array, train nodes\n",
    "* `test_nodes`: np.array, test nodes\n",
    "\n",
    "The function returns a np.array with labels for test nodes and np.array of norms of a distributions difference in each step before convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relational_neighbor(G, threshold, y_train, train_nodes, test_nodes):\n",
    "    conditional = initial_conditional(G, y_train, train_nodes, test_nodes)\n",
    "    diffs = []\n",
    "    while True:\n",
    "        next_conditional = update_conditional(G, conditional, test_nodes)\n",
    "        diff = np.linalg.norm(conditional[test_nodes] - next_conditional[test_nodes])\n",
    "        if diff < threshold:\n",
    "            break\n",
    "        diffs.append(diff)\n",
    "        conditional = next_conditional\n",
    "    return np.argmax(conditional[test_nodes], axis=1), diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `initial_conditional` that returns np.array with initial conditional distribution where $i$-th row represents probability of belonging of node $i$ to each class. Parameters are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "545290b72bb835d731aab3faf367250e",
     "grade": false,
     "grade_id": "cell-6a324ac9fd641225",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initial_conditional(G, y_train, train_nodes, test_nodes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "530fef5d034dc05aa1c81aa42a5d9d88",
     "grade": true,
     "grade_id": "cell-8531b1de992d936c",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "conditional = initial_conditional(G, y_train, train_nodes, test_nodes)\n",
    "assert conditional.shape == (3873, 4)\n",
    "assert np.all(conditional.sum(axis=1) == 1)\n",
    "assert np.all(conditional[test_nodes] == 0.25)\n",
    "assert set(np.unique(conditional[train_nodes])) == {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `update_conditional` that updates and returns np.array with conditional distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2959373b5ba522dcf27a33637fbd9d66",
     "grade": false,
     "grade_id": "cell-ff6c82cd94e48f4d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def update_conditional(G, conditional, test_nodes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2162fee2611ed5b4f3ecdc7eb789d273",
     "grade": true,
     "grade_id": "cell-152e1da0674bfa21",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "conditional = update_conditional(G, conditional, test_nodes)\n",
    "assert conditional.shape == (3873, 4)\n",
    "assert np.all(conditional.sum(axis=1).round(4) == 1)\n",
    "assert set(np.unique(conditional[train_nodes])) == {0, 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An animation of convergence of the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dc401bd730f3cb89e3f44e3f9e117090",
     "grade": true,
     "grade_id": "cell-08c28b32ff6cda6c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred, diffs = relational_neighbor(G, 0.001, y_train, train_nodes, test_nodes)\n",
    "score = balanced_accuracy_score(y_test, y_pred)\n",
    "assert len(diffs) < 40\n",
    "assert score > 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(diffs)\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Difference\")\n",
    "plt.title(\"Convergence\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Balanced accuracy:\", round(score, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, a random guess is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = balanced_accuracy_score(\n",
    "    y_test, np.random.choice(range(4), size=len(test_nodes), replace=True)\n",
    ")\n",
    "print(\"Balanced accuracy:\", round(score, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3. Label propagation by random walks (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the label propagation algorithm on an artificial dataset consisting of 3 sinusoids with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 600\n",
    "np.random.seed(0)\n",
    "x_space = np.linspace(0, 3 * np.pi, int(N / 3))\n",
    "x1 = x_space + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "y1 = np.sin(x_space) + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "x2 = x_space + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "y2 = np.sin(x_space) + np.random.normal(0, 0.2, x_space.shape[0]) - 1.3\n",
    "x3 = x_space + np.random.normal(0, 0.2, x_space.shape[0])\n",
    "y3 = np.sin(x_space) + np.random.normal(0, 0.2, x_space.shape[0]) - 2.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_points = np.stack(\n",
    "    [np.concatenate([x1, x2, x3]), np.concatenate([y1, y2, y3])], axis=1\n",
    ")\n",
    "plt.scatter(\n",
    "    data_points[:, 0],\n",
    "    data_points[:, 1],\n",
    "    c=np.repeat([\"tab:red\", \"tab:orange\", \"tab:green\"], 200),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a graph of k-neighbors of the data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = kneighbors_graph(data_points, n_neighbors=8)\n",
    "G = nx.Graph(A)\n",
    "pos = {i: loc for i, loc in enumerate(data_points)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 20 random train nodes. The goal is to predict an index of the sinusoid for other nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_nodes = np.random.choice(G, size=20, replace=False)\n",
    "test_nodes = np.array(list(set(range(N)).difference(train_nodes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array([0] * 200 + [1] * 200 + [2] * 200)\n",
    "y_train = labels[train_nodes]\n",
    "y_test = labels[test_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw the graph where train nodes are highlighted by colors with respect to a label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[train_nodes[y_train == 0]] = plt.cm.tab10(3)[:3]\n",
    "node_color[train_nodes[y_train == 1]] = plt.cm.tab10(1)[:3]\n",
    "node_color[train_nodes[y_train == 2]] = plt.cm.tab10(2)[:3]\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    node_size=50,\n",
    "    width=0.5,\n",
    "    linewidths=0.3,\n",
    "    edgecolors=\"black\",\n",
    "    node_color=node_color,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label propagation method is also assume that closer data points tend to have similar class labels. Let us denote $Y$ as given label matrix, whose $i$-th row representing the label probability distribution of node $i$. Initialization of rows corresponding to unlabeled data points is not important, but let it be a uniform distribution. The algorithm is\n",
    "1. Propagate $Y \\leftarrow PY$ where $P$ is a transition matrix\n",
    "2. Recover rows of $Y$ corresponding to labeled data points\n",
    "3. Row-normalize $Y$ to maintain probability interpretation\n",
    "4. Repeat 1-3 until $Y$ converges\n",
    "5. Make a prediction as the most likely labels "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a function `label_propagation` that returns predicted labels. Parameters are the same as in the previuos task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_propagation(G, threshold, y_train, train_nodes, test_nodes):\n",
    "    Y = initital_Y(G, y_train, train_nodes, test_nodes)\n",
    "    P = transition_matrix(G)\n",
    "    while True:\n",
    "        nextY = update_Y(P, Y, y_train, train_nodes, test_nodes)\n",
    "        if np.linalg.norm(nextY - Y) < threshold:\n",
    "            break\n",
    "        Y = nextY\n",
    "    y_pred = np.argmax(Y, axis=1)[test_nodes]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `initital_Y` that returns np.array with initial label matrix. Parameters are the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56980aeeb3fcbab49fb111b90f81e18c",
     "grade": false,
     "grade_id": "cell-cd31c29674b345de",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def initital_Y(G, y_train, train_nodes, test_nodes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6866760590408a26fb6d170a1029ae2f",
     "grade": true,
     "grade_id": "cell-1a04c6f5b5d7fc54",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Y = initital_Y(G, y_train, train_nodes, test_nodes)\n",
    "assert Y.shape == (len(G), len(set(y_train)))\n",
    "assert np.all(Y.sum(axis=1) == 1)\n",
    "assert Y[train_nodes].max() == 1\n",
    "assert Y[train_nodes].min() == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `transition_matrix` that returns np.array with transition matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f521b5642f1380a572d2114a19462a6a",
     "grade": false,
     "grade_id": "cell-6ed1f2824e9c5ebe",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def transition_matrix(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c459aaa573094da846bfc4ccfad8f61",
     "grade": true,
     "grade_id": "cell-0667369a810f6b0a",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "P = transition_matrix(G)\n",
    "assert P.shape == (len(G), len(G))\n",
    "assert np.all(P.sum(axis=1).round(4) == 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `update_Y` that returns np.array with updated label matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "014f8afadd10040f0e6b7e03893f7f82",
     "grade": false,
     "grade_id": "cell-cade5b7096d69205",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def update_Y(P, Y, y_train, train_nodes, test_nodes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d8370178449a3c7f103a74a165281a1e",
     "grade": true,
     "grade_id": "cell-0758fdb55082dda0",
     "locked": true,
     "points": 0.5,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "nextY = update_Y(P, Y, y_train, train_nodes, test_nodes)\n",
    "assert nextY.shape == (len(G), len(set(y_train)))\n",
    "assert np.all(nextY.sum(axis=1).round(4) == 1)\n",
    "assert nextY[train_nodes].max() == 1\n",
    "assert nextY[train_nodes].min() == 0\n",
    "\n",
    "y_pred = label_propagation(G, 0.001, y_train, train_nodes, test_nodes)\n",
    "assert balanced_accuracy_score(y_test, y_pred) > 0.93"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color[test_nodes[y_pred == 0]] = plt.cm.tab10(3)[:3]\n",
    "node_color[test_nodes[y_pred == 1]] = plt.cm.tab10(1)[:3]\n",
    "node_color[test_nodes[y_pred == 2]] = plt.cm.tab10(2)[:3]\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    node_size=50,\n",
    "    width=0.5,\n",
    "    linewidths=0.3,\n",
    "    edgecolors=\"black\",\n",
    "    node_color=node_color,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4. Tikhonov regularization on graphs (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider node regression with Tikhonov ($L_2$, Ridge) regularization on an artificial dataset that was again converted into graph by k-neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 600\n",
    "data_points, labels = make_moons(n_samples=N, noise=0.15, random_state=0)\n",
    "A = kneighbors_graph(data_points, n_neighbors=5).toarray()\n",
    "G = nx.Graph(A)\n",
    "pos = {i: loc for i, loc in enumerate(data_points)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "train_nodes = np.random.choice(G, size=20, replace=False)\n",
    "test_nodes = np.array(list(set(range(N)).difference(train_nodes)))\n",
    "labels[labels == 0] = 10\n",
    "labels[labels == 1] = 100\n",
    "y_train = labels[train_nodes]\n",
    "y_test = labels[test_nodes]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are labels of blue nodes equal to 10, reds equal to 100. Other labels are unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = np.ones((len(G), 3)) * 0.9\n",
    "node_color[train_nodes[y_train == 10]] = plt.cm.coolwarm(0)[:3]\n",
    "node_color[train_nodes[y_train == 100]] = plt.cm.coolwarm(255)[:3]\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    node_size=50,\n",
    "    width=0.5,\n",
    "    linewidths=0.3,\n",
    "    edgecolors=\"black\",\n",
    "    node_color=node_color,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider given node labels $\\mathbf y$ and normalized labels\n",
    "\n",
    "$$\\tilde y_i = y_i - \\frac{1}{k}\\sum_{j=1}^k y_j$$ \n",
    "\n",
    "where $k$ is the number of known labels. Unknown labels are given as zeros $\\tilde y_i = 0$. Also let $\\mathbf f$ be predicted labels of nodes. The objective is to minimize the square loss function plus the smoothness penalty\n",
    "\n",
    "$$\\mathbf{\\tilde f} = \\text{argmin}_\\mathbf{f}\\left(\\frac{1}{k}\\sum_{i=1}^k(f_i - \\tilde y_i)^2 + \\gamma \\mathbf{f}^T L \\mathbf{f}\\right)$$\n",
    "\n",
    "where $L$ is a graph Laplacian. The analytical solution is given as\n",
    "\n",
    "$$\\mathbf{\\tilde f} = (k \\gamma L + I)^{-1}\\mathbf{\\tilde y}$$\n",
    "\n",
    "where $I$ is a diagonal matrix with ones and zeros. $I_{ii} = 1$ if a label of $i$-th node is known.\n",
    "\n",
    "_Remark: for the stability of the algorithm, we use $\\tilde y_i$ instead of $y_i$._\n",
    "\n",
    "Write a function `tikhonov_regularization` that takes the same parameters as above (`gamma` is a coefficient of regularization), and returns predicted labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0659a1224e4481e8b07f113eeaf33241",
     "grade": false,
     "grade_id": "cell-83dad7d0900b8f54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def tikhonov_regularization(G, gamma, y_train, train_nodes, test_nodes):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "495b630591aea0dcb4b4912a7378eff2",
     "grade": true,
     "grade_id": "cell-fa1ad892d4ee589e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "y_pred = tikhonov_regularization(G, 0.001, y_train, train_nodes, test_nodes)\n",
    "assert mean_squared_error(y_test, y_pred) < 282"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "for i, gamma in enumerate([0.01, 0.5]):\n",
    "    y_pred = tikhonov_regularization(G, gamma, y_train, train_nodes, test_nodes)\n",
    "    node_color = labels\n",
    "    node_color[test_nodes] = y_pred\n",
    "    plt.subplot(1, 2, i + 1)\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        node_size=50,\n",
    "        width=0.5,\n",
    "        linewidths=0.3,\n",
    "        node_color=node_color,\n",
    "        edgecolors=\"black\",\n",
    "        cmap=plt.cm.coolwarm,\n",
    "    )\n",
    "    plt.title(\"gamma: {}\".format(gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5. SVD node embeddings (1 point)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the simplest way to obtain node embeddings is to use SVD of adjacency matrix.\n",
    "\n",
    "The first step is to decompose the adjacency matrix $A$ into three matrices $U$\n",
    ", $S$ and $V$ so that \n",
    "\n",
    "$$USV^T = A$$\n",
    "\n",
    "Then we keep only $k$ first singular values, where $k$ is a number of dimensions of embedding. For example if $k=2$, then the 4x4 matrix $S$ is converted as follows\n",
    "\n",
    "$$S = \\begin{bmatrix}\n",
    "\\sigma_1 & 0 & 0 & 0 \\\\\n",
    "0 & \\sigma_2 & 0 & 0 \\\\\n",
    "0 & 0 & \\sigma_3 & 0 \\\\\n",
    "0 & 0 & 0 & \\sigma_4 \\\\\n",
    "\\end{bmatrix}\n",
    "\\Rightarrow\n",
    "\\begin{bmatrix}\n",
    "\\sigma_1 & 0 & 0 & 0 \\\\\n",
    "0 & \\sigma_2 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "0 & 0 & 0 & 0 \\\\\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "And then we compute embeddings as $E = US$ and use only non-zero columns. Let us consider SVD embedding on the Zachary's Karate Club graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `svd_adj` that takes a graph and returns 3 np.arrays with $U$, $S$, $V^T$ of an adjacency matrix. \n",
    "\n",
    "Hint: use `np.linalg.svd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a1d72000a04f7d7610da540ef9e97f6b",
     "grade": false,
     "grade_id": "cell-9da3cd75a2c870cf",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def svd_adj(G):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "29cd49c992ce7caba8457166294bc603",
     "grade": true,
     "grade_id": "cell-9916cee422e7e71a",
     "locked": true,
     "points": 0,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "G = nx.karate_club_graph()\n",
    "A = nx.to_numpy_array(G)\n",
    "u, s, vt = svd_adj(G)\n",
    "A_ = u @ s @ vt\n",
    "assert np.allclose(A, A_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function `svd_embedding` that takes np.arrays with $U$, $S$, a numer of dimensions $k$ and returns a np.array with node embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "cebda4dc4d8f100434ebe7141675253c",
     "grade": false,
     "grade_id": "cell-b71bd633032058ce",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def svd_embedding(u, s, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "07358ffdd8051376d1ecdc2313e9222a",
     "grade": true,
     "grade_id": "cell-db2be10d307ead94",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "attr = nx.get_node_attributes(G, \"club\")\n",
    "attr = [\"tab:orange\" if i == \"Mr. Hi\" else \"tab:blue\" for i in list(attr.values())]\n",
    "\n",
    "G = nx.karate_club_graph()\n",
    "u, s, vt = svd_adj(G)\n",
    "\n",
    "emb = svd_embedding(u, s, 2)\n",
    "assert emb.shape == (34, 2)\n",
    "\n",
    "clf = LogisticRegression().fit(emb, attr)\n",
    "assert 0.97 < clf.score(emb, attr) < 1\n",
    "\n",
    "emb = svd_embedding(u, s, 8)\n",
    "assert emb.shape == (34, 8)\n",
    "\n",
    "clf = LogisticRegression().fit(emb, attr)\n",
    "assert clf.score(emb, attr) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = svd_embedding(u, s, 2)\n",
    "plt.scatter(emb[:, 0], emb[:, 1], c=attr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, SVD embeddings give linearly seperable classes for the karate club graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6. DeepWalk node embeddings (3 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepWalk is an approach for learning latent representations of nodes in a network. These latent representations encode social relations in a continuous vector space, which is easily exploited by statistical models. The idea here is that each random walk is considered as a sentence where each node is a word. The algorithm is divided into two steps:\n",
    "1. Generate random walks\n",
    "2. Encode a matrix of random walks into low-dimensional space using SkipGram architcture with Hierarchical Softmax\n",
    "\n",
    "Write a function `random_walks` that takes a graph, number of random walks `n_walks` starting from every node, path length of walk `path_length`. The function returns a np.array of a shape `(n_walks * N, path_length)` where `N` is number of nodes and every row is a single random path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "56d8420531b8d3aa47b0fc85ccc8bced",
     "grade": false,
     "grade_id": "cell-0432b1f937393623",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def random_walks(G, n_walks, path_length):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7d0dfa7eeca2ae30e33299147e7c7a1a",
     "grade": true,
     "grade_id": "cell-271af1d8dbe3c64d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "G = nx.karate_club_graph()\n",
    "walks = random_walks(G, 10, 5)\n",
    "\n",
    "assert walks.shape == (34 * 10, 5)\n",
    "for i, j in zip(walks[0, :-1], walks[0, 1:]):\n",
    "    assert G.has_edge(i, j)\n",
    "assert np.all(walks[:, 0] == np.repeat(np.arange(34), 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us apply Word2Vec model for embedding nodes into 2D space. \n",
    "\n",
    "Write a function `encode` that takes a np.array with random walks, a graph `G` and returns a np.array with k-D embeddings, each row is a node.\n",
    "\n",
    "_Hints:_\n",
    "* _Convert the random walks matrix from np.array into list of lists with string entries_\n",
    "* _Create a model `gensim.models.word2vec.Word2Vec` with k-D embedding (`size=k`)_\n",
    "* _Make sure that Hierarchical Softmax is turn on (`hs=1`) and SkipGram is turn on (`sg=1`)_\n",
    "* _Adjust parameters: window size `window`, learning rate `alpha`, number of epochs `iter`_\n",
    "* _`model.wv` contains obtained embeddings_\n",
    "* _Check the drawing: nodes should be close to each other if they have similar neighbors_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "23bae240d0e19b3f0ef40e2f3768baae",
     "grade": false,
     "grade_id": "cell-3e6a262e06d86226",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def encode(walks, k):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "fe942e80b5df210617f28ebb4a5a6f8c",
     "grade": true,
     "grade_id": "cell-1aa61a2423f0f267",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "emb = encode(walks, 2)\n",
    "assert emb.shape == (34, 2)\n",
    "\n",
    "assert np.linalg.norm(emb[0] - emb[11]) < np.linalg.norm(emb[0] - emb[33])\n",
    "assert np.linalg.norm(emb[1] - emb[2]) < np.linalg.norm(emb[1] - emb[32])\n",
    "\n",
    "emb = encode(walks, 10)\n",
    "assert emb.shape == (34, 10)\n",
    "\n",
    "attr = nx.get_node_attributes(G, \"club\")\n",
    "attr = [\"tab:orange\" if i == \"Mr. Hi\" else \"tab:blue\" for i in list(attr.values())]\n",
    "clf = LogisticRegression().fit(emb, attr)\n",
    "assert clf.score(emb, attr) > 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = encode(walks, 2)\n",
    "pos = {i: emb[i] for i in range(34)}\n",
    "node_color = [\n",
    "    2,\n",
    "    2,\n",
    "    3,\n",
    "    2,\n",
    "    1,\n",
    "    1,\n",
    "    1,\n",
    "    2,\n",
    "    0,\n",
    "    3,\n",
    "    1,\n",
    "    2,\n",
    "    2,\n",
    "    2,\n",
    "    0,\n",
    "    0,\n",
    "    1,\n",
    "    2,\n",
    "    0,\n",
    "    2,\n",
    "    0,\n",
    "    2,\n",
    "    0,\n",
    "    0,\n",
    "    3,\n",
    "    3,\n",
    "    0,\n",
    "    3,\n",
    "    3,\n",
    "    0,\n",
    "    0,\n",
    "    3,\n",
    "    0,\n",
    "    0,\n",
    "]\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "nx.draw_kamada_kawai(G, with_labels=True, node_color=node_color, cmap=plt.cm.tab10)\n",
    "plt.title(\"Kamada-Kawai layout\")\n",
    "plt.subplot(1, 2, 2)\n",
    "nx.draw(G, pos, with_labels=True, node_color=node_color, cmap=plt.cm.tab10)\n",
    "plt.title(\"2D DeepWalk embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
